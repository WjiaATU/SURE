{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2c0401c1dc398ee73f03e595e669f026a0c6e013d58009def37dd9d643997cb8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classify handwritten digits -- MNIST\n",
    "\n",
    "Let's look at a concrete example of a neural network that uses the Python library Keras to learn to classify handwritten digits.\n",
    "\n",
    "The problem we're trying to solve here is to classify graysacle images of handwritten digits (28 * 28 pixels) into their 10 categories (0 through 9). We'll use the MNIST dataset, a classic in the machine-learning community, which has been around almost as long as the field itself and has been intensively studied. \n",
    "\n",
    "##### About MNIST \n",
    "It's a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. \n",
    "\n",
    "You can think of \"solving\" MNIST as the \"Hello World\" of deep learning -- it's what you do to verify that your algorithms are working as expected. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28)\n(10000, 28, 28)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Loading the MNIST dataset in Keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Let's look at the training data\n",
    "print(train_images.shape)\n",
    "len(train_labels)\n",
    "\n",
    "# Then the test data\n",
    "print(test_images.shape)\n",
    "len(test_labels)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network architecture\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "### The compilation step\n",
    "\n",
    "network.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Question 1\n",
    "1.1 How many images are there in the training data?\n",
    "\n",
    "1.2 How many images in the testing data?\n",
    "\n",
    "1.3 How many layers are there in the neural network above?\n",
    "\n",
    "1.4 What was the optimizer chosen in the example above? What other optimizers do you know in the deep learning models?\n",
    "\n",
    "1.5 Why 'categorical_crossentropy', not 'mean_squared_error' was used as the loss function?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "### Preparing the image data\n",
    "\n",
    "### We transform the training image data into a float32 array of shape (60000, 28*28) with values between 0 and 1\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "\n",
    "### Similarly for the testing data\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "### We also need to categorically encode the labels\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# print(train_labels.shape)\n",
    "# print(test_labels.shape)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# print(train_labels.shape)\n",
    "# print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2555 - accuracy: 0.9265\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1031 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0681 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0493 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0369 - accuracy: 0.9891\n",
      "10000/10000 [==============================] - 1s 133us/step\n",
      "test_acc:  0.98089998960495\n"
     ]
    }
   ],
   "source": [
    "### Train the network;\n",
    "network.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "\n",
    "### Make prediction on the testing data;\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "source": [
    "## Question 2\n",
    "2.1 Please use the '.shape' function to compare the shape of training or testing data before and after transformation. What is the shape of the train_images when training the network by network.fit()?\n",
    "\n",
    "2.2 What is the accuracy on the training data? \n",
    "\n",
    "2.3 What is the accuracy on the testing data?\n",
    "\n",
    "2.4 Please repeat the procedure above for 5 times. Did the training accuracy and testing accuracy change?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify handwritten digits -- MNIST\n",
    "\n",
    "Let's look at a concrete example of a neural network that uses the Python library Keras to learn to classify handwritten digits.\n",
    "\n",
    "The problem we're trying to solve here is to classify graysacle images of handwritten digits (28 * 28 pixels) into their 10 categories (0 through 9). We'll use the MNIST dataset, a classic in the machine-learning community, which has been around almost as long as the field itself and has been intensively studied. \n",
    "\n",
    "##### About MNIST \n",
    "It's a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. \n",
    "\n",
    "You can think of \"solving\" MNIST as the \"Hello World\" of deep learning -- it's what you do to verify that your algorithms are working as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the MNIST dataset in Keras\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Let's look at the training data\n",
    "print(train_images.shape)\n",
    "len(train_labels)\n",
    "\n",
    "# Then the test data\n",
    "print(test_images.shape)\n",
    "len(test_labels)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network architecture\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "### The compilation step\n",
    "\n",
    "network.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\r\n",
    "1.1 How many images are there in the training data?\r\n",
    "\r\n",
    "Solution: There are 60,000 images in the training data. Each image is in grayscale with 28*28 pixels.\r\n",
    "\r\n",
    "1.2 How many images in the testing data?\r\n",
    "\r\n",
    "Solution: There are 10,000 images in the testing data.\r\n",
    "\r\n",
    "1.3 How many layers are there in the neural network above?\r\n",
    "\r\n",
    "Solution: There are one input layer, one hidden layer, and one output layer in this neural network. Here, our network consists of a sequence of two Dense layers, which are densly connected (also called fully connected) neural layers. The second (and last) layer is a 10-way softmax layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes. \r\n",
    "\r\n",
    "1.4 What was the optimizer chosen in the example above? What other optimizers do you know in the deep learning models?\r\n",
    "\r\n",
    "Solution: The optimixer chosen in this example is \"rmsprop\".\r\n",
    "Generally, there are families of optimizers: 1. Gradient Descent Optimizers, e.g. SGD in Keras; 2. Adaptive optimizers, e.g. RMSprop, Adam.\r\n",
    "\r\n",
    "1.5 Why 'categorical_crossentropy', not 'mean_squared_error' was used as the loss function?\r\n",
    "\r\n",
    "Solution: Because this question is a classification problem, ‘categorical_crossentropy’ is commonly used for this type of quesiton. For regression problems, 'mean-squared_error' is more common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing the image data\n",
    "\n",
    "### We transform the training image data into a float32 array of shape (60000, 28*28) with values between 0 and 1\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "\n",
    "### Similarly for the testing data\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "### We also need to categorically encode the labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# print(train_labels.shape)\n",
    "# print(test_labels.shape)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# print(train_labels.shape)\n",
    "# print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2564 - accuracy: 0.9254\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1020 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0678 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0493 - accuracy: 0.9851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0368 - accuracy: 0.9886\n",
      "10000/10000 [==============================] - 1s 107us/step\n",
      "test_acc:  0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "### Train the network;\n",
    "network.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "\n",
    "### Make prediction on the testing data;\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\r\n",
    "2.1 Please use the '.shape' function to compare the shape of training or testing data before and after transformation. What is the shape of the train_images when training the network by network.fit()?\r\n",
    "\r\n",
    "Solution: Previously, the training images were stored in an array of shape (60000, 28, 28) of type\r\n",
    "uint8 with values in the [0, 255] interval. We transform it into a float32 array of\r\n",
    "shape (60000, 28 * 28) with values between 0 and 1.\r\n",
    "\r\n",
    "What is uint8 in Numpy? Range from 0 to 255. Pixels are uint8 [0,255].\r\n",
    "What is float32 in Numpy? numpy.float32 is a single precision float. It's double precision counterpart is numpy.float64.\r\n",
    "\r\n",
    "2.2 What is the accuracy on the training data? \r\n",
    "\r\n",
    "Solution: 98.86%\r\n",
    "\r\n",
    "\r\n",
    "2.3 What is the accuracy on the testing data?\r\n",
    "\r\n",
    "Solution: 97.83%\r\n",
    "\r\n",
    "2.4 Please repeat the procedure above for 5 times. Did the training accuracy and testing accuracy change?\r\n",
    "\r\n",
    "Solution: Yes, it changes along with the different ways to have the epoches."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c0401c1dc398ee73f03e595e669f026a0c6e013d58009def37dd9d643997cb8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
